{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eebf6378-4226-4c0e-be58-39712215020f",
   "metadata": {},
   "source": [
    "# DAV Lab 4 Homework\n",
    "- Name:\n",
    "- Roll No:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5620ee9-b1b8-4ec3-92e0-f00005377127",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Lets build a sentiment Analysis model, which can detect given a phrase/sentence, if its positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ef27a36-7bea-462c-a1d1-7a5bc1dd6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd99bf-b591-4941-b6c1-c5037c08ced3",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Sentiment Analysis is the process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer’s attitude towards a particular topic, product, etc. is positive, negative, or neutral.\n",
    "\n",
    "This is a simple project of classifying the movie reviews as either positive or negative. We would be working on the ‘movie_reviews’ dataset in ntlk.corpus package\n",
    "\n",
    "## Tasks\n",
    "### EDA\n",
    "1. Check the size of the corpus using `len()`. This will give you the total number of reviews in the corpus.\n",
    "1. Check the categories in the corpus using categories(). This will give you a list of the two categories(\"neg\" and \"pos\").Which indicate whether a review is negative or positive.\n",
    "1. Count the number of positive and negative reviews using a loop and `fileids()`. This will give you an idea of the distribution of reviews in the corpus.\n",
    "1. View a specific review using `raw()` and `fileids()`. This will allow you to read a review in its raw text form.\n",
    "1. Perform tokenization using `word_tokenize()` or `sent_tokenize()`. This will allow you to see how the reviews are broken down into individual words or sentences.\n",
    "1. Perform part-of-speech (POS) tagging using `pos_tag()`. This will allow you to see how different parts of speech are used in the reviews.\n",
    "1. Create a list of all reviews in the corpus, with their respective categories.\n",
    "## Model Building\n",
    "1. Create a list of stop words using `stopwords.words('english')` and remove them from the text using a list comprehension. This will remove common words like \"the\", \"and\", and \"a\" that do not add much meaning to the text.\n",
    "1. Convert the words to lowercase using `lower()`. This will ensure that words with different capitalizations are treated as the same word.\n",
    "1. Use `FreqDist()` to create a frequency distribution of the most common words in the corpus. You can specify the number of most common words to include using the `most_common()` method.\n",
    "1. Create a feature set from the most common words by creating a list of tuples where each tuple contains a dictionary of features and the corresponding category of the review (i.e., \"neg\" or \"pos\"). The dictionary of features should contain the most common words as keys and their frequencies in each review as values.\n",
    "1. Shuffle the feature set using `random.shuffle()` to ensure that the training and test sets are representative of the overall corpus.\n",
    "1. Split the feature set into a training set and a test set using a 80/20 split. This will allow you to train the classifier on a portion of the data and test its accuracy on the remaining data.\n",
    "1. Train a naive Bayes classifier using `nltk.classify.NaiveBayesClassifier.train()` and the training set of features.\n",
    "1. Test the accuracy of the classifier on the test set using `nltk.classify.accuracy()`.\n",
    "1. Show the most informative features using `classifier.show_most_informative_features(10)`\n",
    "1. Experiment with different numbers of most common words and different thresholds for including words in the feature set to see how they affect the accuracy of the classifier.\n",
    "\n",
    "## References\n",
    "1. https://www.nltk.org/howto/sentiment.html\n",
    "2. https://www.analyticsvidhya.com/blog/2021/06/sentiment-analysis-using-nltk-a-practical-approach/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2960ce1-994a-43f0-8a14-b37a622dcdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] <urlopen error [Errno 104] Connection reset by peer>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download([ \"stopwords\", \"movie_reviews\", \"punkt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4ca20c8-9377-4171-8a2c-4f92b0aa9c42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prints total number of words in 'movie_reviews'\n",
    "\n",
    "# Print the review categories\n",
    "\n",
    "# Prints all file ids\n",
    "\n",
    "# Prints file ids of positive reviews\n",
    "\n",
    "# Prints file ids of negative reviews."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
